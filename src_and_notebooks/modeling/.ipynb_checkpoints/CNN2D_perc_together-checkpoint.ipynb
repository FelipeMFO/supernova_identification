{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../processing/read_data.py\n",
    "%run ../processing/functions.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Conv3D, MaxPooling3D, ZeroPadding3D\n",
    "# Helper libraries\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_read = '../../data/dl_marcelo_perc/'\n",
    "files = []\n",
    "\n",
    "for r, d, f in os.walk(path_to_read):\n",
    "    for file in f:\n",
    "        if '.png' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "files.sort()\n",
    "np_files = np.asarray(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84954"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion = {'IIL_' : 5, 'IIP_' : 7, '_II_' : 4, 'IIn_' : 6, '_Ia_' : 0, '_Ib_' : 1, 'Ibc_' : 2, '_Ic_' : 3}\n",
    "conversion_bool = {'IIL_' : 0, 'IIP_' : 0, '_II_' : 0, 'IIn_' : 0, '_Ia_' : 1, '_Ib_' : 0, 'Ibc_' : 0, '_Ic_' : 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [0,0,0,0]\n",
    "idx = []\n",
    "i = 0\n",
    "while i < len(np_files):\n",
    "    if 'desg' in np_files[i]:\n",
    "        c[0] = 1\n",
    "    if 'desi' in np_files[i+1]:\n",
    "        c[1] = 1\n",
    "    if 'desr' in np_files[i+2]:\n",
    "        c[2] = 1\n",
    "    if 'desz' in np_files[i+3]:\n",
    "        c[3] = 1\n",
    "    if c == [1,1,1,1]:\n",
    "        i = i + 4\n",
    "        c = [0,0,0,0]\n",
    "    elif c[1] == 0:\n",
    "        idx.append(i)\n",
    "        i = i+1\n",
    "    elif c[2] == 0:\n",
    "        idx.append(i)\n",
    "        idx.append(i+1)\n",
    "        i = i+2\n",
    "    elif c[3] == 0:\n",
    "        idx.append(i)\n",
    "        idx.append(i+1)  \n",
    "        idx.append(i+2)\n",
    "        i = i+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84928"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_files = np.delete(np_files, idx)\n",
    "len(np_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantity of objects is:  21232\n"
     ]
    }
   ],
   "source": [
    "np_grouped = np_files.reshape(round(np_files.shape[0]/4), 4)\n",
    "class_id = []\n",
    "#CHANGE HERE THE INDEX EVERYTIME WE CHANGE THE NAME FROM THE PATH OF THE FOLDER\n",
    "for g in np_grouped:\n",
    "    class_id = class_id + [[g[0][-20:-12], g[0][-12:-8]]] \n",
    "types = []\n",
    "types_bool = []\n",
    "for ids in class_id:\n",
    "    types = types + [conversion[ids[1]]]\n",
    "    types_bool = types_bool + [conversion_bool[ids[1]]]\n",
    "    \n",
    "astr_objs = []\n",
    "for i in range(len(np_grouped)):\n",
    "    astr_objs = astr_objs + [class_id[i]]\n",
    "    for file in np_grouped[i]:\n",
    "        img = Image.open(file).convert('L')\n",
    "        arr = np.array(img)\n",
    "        astr_objs[-1] = astr_objs[-1] + [arr[5:35,10:56]] \n",
    "        #CHANGE HERE IF WE EVENTUALLY CHANGE THE SIZE OF THE IMAGE, OR WANT TO CUT OTHER FRAMES\n",
    "\n",
    "print( \"The quantity of objects is: \", len(astr_objs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 4247  4248  4249 ... 21229 21230 21231] TEST: [   0    1    2 ... 4244 4245 4246]\n",
      "TRAIN: [    0     1     2 ... 21229 21230 21231] TEST: [4247 4248 4249 ... 8491 8492 8493]\n",
      "TRAIN: [    0     1     2 ... 21229 21230 21231] TEST: [ 8494  8495  8496 ... 12737 12738 12739]\n",
      "TRAIN: [    0     1     2 ... 21229 21230 21231] TEST: [12740 12741 12742 ... 16983 16984 16985]\n",
      "TRAIN: [    0     1     2 ... 16983 16984 16985] TEST: [16986 16987 16988 ... 21229 21230 21231]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "images = []\n",
    "ids = []\n",
    "for o in astr_objs:\n",
    "    labels.append((conversion_bool[o[1]])) #converting here to numbers to assure label in training\n",
    "    desg = o[2]\n",
    "    desi = o[3]\n",
    "    desr = o[4]\n",
    "    desz = o[5]\n",
    "    gather = np.concatenate((desg,desi,desr,desz),axis = 1)\n",
    "    images.append(gather)\n",
    "    ids.append(o[0])\n",
    "labels = np.asarray(labels)\n",
    "images = np.asarray(images)\n",
    "ids = np.asarray(ids)\n",
    "\n",
    "Xb = images\n",
    "yb = labels\n",
    "kfb = KFold(n_splits=5)\n",
    "Xb_train = []\n",
    "Xb_test = []\n",
    "yb_train = []\n",
    "yb_test = []\n",
    "id_train = []\n",
    "id_test = []\n",
    "for train_index, test_index in kfb.split(Xb):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xb_train.append(Xb[train_index])\n",
    "    Xb_test.append(Xb[test_index])\n",
    "    yb_train.append(yb[train_index])\n",
    "    yb_test.append(yb[test_index])\n",
    "    id_train.append(ids[train_index])\n",
    "    id_test.append(ids[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the objects are:\n",
      "ids:  (21232,)\n",
      "labels:  (21232,)\n",
      "images:  (21232, 30, 184)\n",
      "train_images:  (16985, 30, 184)\n",
      "Other useful object: \"test_images\"\n"
     ]
    }
   ],
   "source": [
    "print('The shapes of the objects are:')\n",
    "print('ids: ', ids.shape)\n",
    "print('labels: ', labels.shape)\n",
    "print('images: ', images.shape)\n",
    "print('train_images: ', Xb_train[0].shape)\n",
    "print('Other useful object: \"test_images\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-603c25abde75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#This cell bugs the pc a little\n",
    "#Normalization and separating the folds to the models\n",
    "img_rows, img_cols = 30, 184\n",
    "input_shape = (img_cols, img_rows)\n",
    "\n",
    "train_images = np.around(Xb_train[0]/255, decimals = 2)\n",
    "test_images = np.around(Xb_test[0]/255, decimals = 2)\n",
    "\n",
    "x_train = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "#train_images1 = np.around(Xb_train[1]/255, decimals = 2)\n",
    "#test_images1 = np.around(Xb_test[1]/255, decimals = 2)\n",
    "\n",
    "#x_train1 = train_images1.reshape(train_images1.shape[0], img_rows, img_cols, 1)\n",
    "#\n",
    "#\n",
    "#train_images2 = np.around(Xb_train[2]/255, decimals = 2)\n",
    "#test_images2 = np.around(Xb_test[2]/255, decimals = 2)\n",
    "#\n",
    "#x_train2 = train_images2.reshape(train_images2.shape[0], img_rows, img_cols, 1)\n",
    "#\n",
    "#\n",
    "#train_images3 = np.around(Xb_train[3]/255, decimals = 2)\n",
    "#test_images3 = np.around(Xb_test[3]/255, decimals = 2)\n",
    "#\n",
    "#x_train3 = train_images3.reshape(train_images3.shape[0], img_rows, img_cols, 1)\n",
    "#\n",
    "#\n",
    "train_images4 = np.around(Xb_train[4]/255, decimals = 2)\n",
    "test_images4 = np.around(Xb_test[4]/255, decimals = 2)\n",
    "\n",
    "x_train4 = train_images4.reshape(train_images4.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Convolution NN 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/felipematheus/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/felipematheus/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 184, 30, 64)       1088      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 184, 30, 64)       36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 92, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 92, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 46, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20608)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 41218     \n",
      "=================================================================\n",
      "Total params: 116,162\n",
      "Trainable params: 116,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "img_rows, img_cols = 30, 184\n",
    "input_shape = (img_cols, img_rows,1)\n",
    "\n",
    "model_cv = Sequential()\n",
    "\n",
    "model_cv.add(Conv2D(64, kernel_size=(4,4), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_cv.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model_cv.add(Flatten())\n",
    "model_cv.add(Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "model_cv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9)\n",
    "model_cv.compile(optimizer='adam', #optimizer = 'adadelta'\n",
    "              loss='sparse_categorical_crossentropy', #loss = \"binary_crossentropy\"\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16985/16985 [==============================] - 132s 8ms/sample - loss: 0.4507 - acc: 0.7834\n",
      "Epoch 2/10\n",
      "16985/16985 [==============================] - 136s 8ms/sample - loss: 0.3597 - acc: 0.8218\n",
      "Epoch 3/10\n",
      "16985/16985 [==============================] - 114s 7ms/sample - loss: 0.3404 - acc: 0.8341\n",
      "Epoch 4/10\n",
      "16985/16985 [==============================] - 126s 7ms/sample - loss: 0.3224 - acc: 0.8439\n",
      "Epoch 5/10\n",
      "16985/16985 [==============================] - 126s 7ms/sample - loss: 0.3063 - acc: 0.8543\n",
      "Epoch 6/10\n",
      "16985/16985 [==============================] - 114s 7ms/sample - loss: 0.2984 - acc: 0.8578\n",
      "Epoch 7/10\n",
      "16985/16985 [==============================] - 100s 6ms/sample - loss: 0.2954 - acc: 0.8584\n",
      "Epoch 8/10\n",
      "16985/16985 [==============================] - 102s 6ms/sample - loss: 0.2845 - acc: 0.8676\n",
      "Epoch 9/10\n",
      "16985/16985 [==============================] - 97s 6ms/sample - loss: 0.2774 - acc: 0.8704\n",
      "Epoch 10/10\n",
      "16985/16985 [==============================] - 102s 6ms/sample - loss: 0.2685 - acc: 0.8747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f60c6405128>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "model_cv.fit(x_train, yb_train[0], #validation_split = 0.1\n",
    "             epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Kfold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 46, 30, 64)        4160      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 46, 30, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 23, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 23, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 11, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4928)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 9858      \n",
      "=================================================================\n",
      "Total params: 87,874\n",
      "Trainable params: 87,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "img_rows, img_cols = 30, 184\n",
    "input_shape = (img_cols, img_rows,1)\n",
    "\n",
    "model_cv4 = Sequential()\n",
    "\n",
    "model_cv4.add(Conv2D(64, kernel_size=(4,4), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv4.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_cv4.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model_cv4.add(Flatten())\n",
    "model_cv4.add(Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "model_cv4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9)\n",
    "model_cv4.compile(optimizer='adam', #optimizer = 'adadelta'\n",
    "              loss='sparse_categorical_crossentropy', #loss = \"binary_crossentropy\"\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16986/16986 [==============================] - 107s 6ms/sample - loss: 0.4687 - acc: 0.7786\n",
      "Epoch 2/10\n",
      "16986/16986 [==============================] - 114s 7ms/sample - loss: 0.3693 - acc: 0.8112\n",
      "Epoch 3/10\n",
      "16986/16986 [==============================] - 106s 6ms/sample - loss: 0.3474 - acc: 0.8285\n",
      "Epoch 4/10\n",
      "16986/16986 [==============================] - 108s 6ms/sample - loss: 0.3283 - acc: 0.8384\n",
      "Epoch 5/10\n",
      "16986/16986 [==============================] - 111s 7ms/sample - loss: 0.3092 - acc: 0.8531\n",
      "Epoch 6/10\n",
      "16986/16986 [==============================] - 117s 7ms/sample - loss: 0.3004 - acc: 0.8568\n",
      "Epoch 7/10\n",
      "16986/16986 [==============================] - 118s 7ms/sample - loss: 0.2943 - acc: 0.8611\n",
      "Epoch 8/10\n",
      "16986/16986 [==============================] - 352s 21ms/sample - loss: 0.2858 - acc: 0.8683\n",
      "Epoch 9/10\n",
      "16986/16986 [==============================] - 286s 17ms/sample - loss: 0.2755 - acc: 0.8712\n",
      "Epoch 10/10\n",
      "16986/16986 [==============================] - 282s 17ms/sample - loss: 0.2704 - acc: 0.8748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f60c58342b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "model_cv4.fit(x_train4, yb_train[4], #validation_split = 0.1\n",
    "             epochs=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4247/4247 [==============================] - 52s 12ms/sample - loss: 0.2905 - acc: 0.8656\n",
      "Test accuracy model_cv: 0.8655521\n",
      "Test loss model_cv: 0.290524958609861\n"
     ]
    }
   ],
   "source": [
    "x_test = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "test_loss_cv, test_acc_cv = model_cv.evaluate(x_test, yb_test[0])\n",
    "\n",
    "print('Test accuracy model_cv:', test_acc_cv)\n",
    "print('Test loss model_cv:', test_loss_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4246/4246 [==============================] - 55s 13ms/sample - loss: 0.3014 - acc: 0.8490\n",
      "Test accuracy model_cv: 0.84903437\n",
      "Test loss model_cv: 0.30137312290132806\n"
     ]
    }
   ],
   "source": [
    "x_test4 = test_images4.reshape(test_images4.shape[0], img_rows, img_cols, 1)\n",
    "test_loss_cv4, test_acc_cv4 = model_cv4.evaluate(x_test4, yb_test[4])\n",
    "\n",
    "print('Test accuracy model_cv:', test_acc_cv4)\n",
    "print('Test loss model_cv:', test_loss_cv4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_plot_bug()\n",
    "pred = model_cv.predict(x_test)\n",
    "pred_bool = transform(pred)\n",
    "y_true = yb_test[0]\n",
    "plot_confusion_matrix(y_true, pred_bool, ['Not IA', 'IA'],normalize=True )\n",
    "plot_confusion_matrix(y_true, pred_bool, ['Not IA', 'IA'],normalize=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_cv4.predict(x_test4)\n",
    "pred_bool = transform(pred)\n",
    "y_true = yb_test[4]\n",
    "plot_confusion_matrix(y_true, pred_bool, ['Not IA', 'IA'],normalize=True )\n",
    "plot_confusion_matrix(y_true, pred_bool, ['Not IA', 'IA'],normalize=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
