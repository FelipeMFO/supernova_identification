{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../processing/read_data.py\n",
    "%run ../processing/functions.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Conv3D, MaxPooling3D, ZeroPadding3D\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_read = '../../data/dl_marcelo_stddev/'\n",
    "files = []\n",
    "\n",
    "for r, d, f in os.walk(path_to_read):\n",
    "    for file in f:\n",
    "        if '.png' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "files.sort()\n",
    "np_files = np.asarray(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85197"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion = {'IIL_' : 5, 'IIP_' : 7, '_II_' : 4, 'IIn_' : 6, '_Ia_' : 0, '_Ib_' : 1, 'Ibc_' : 2, '_Ic_' : 3}\n",
    "conversion_bool = {'IIL_' : 0, 'IIP_' : 0, '_II_' : 0, 'IIn_' : 0, '_Ia_' : 1, '_Ib_' : 0, 'Ibc_' : 0, '_Ic_' : 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [0,0,0,0]\n",
    "idx = []\n",
    "i = 0\n",
    "while i < len(np_files):\n",
    "    if 'desg' in np_files[i]:\n",
    "        c[0] = 1\n",
    "    if 'desi' in np_files[i+1]:\n",
    "        c[1] = 1\n",
    "    if 'desr' in np_files[i+2]:\n",
    "        c[2] = 1\n",
    "    if 'desz' in np_files[i+3]:\n",
    "        c[3] = 1\n",
    "    if c == [1,1,1,1]:\n",
    "        i = i + 4\n",
    "        c = [0,0,0,0]\n",
    "    elif c[1] == 0:\n",
    "        idx.append(i)\n",
    "        i = i+1\n",
    "    elif c[2] == 0:\n",
    "        idx.append(i)\n",
    "        idx.append(i+1)\n",
    "        i = i+2\n",
    "    elif c[3] == 0:\n",
    "        idx.append(i)\n",
    "        idx.append(i+1)  \n",
    "        idx.append(i+2)\n",
    "        i = i+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85160"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_files = np.delete(np_files, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_grouped = np_files.reshape(round(np_files.shape[0]/4), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/felipematheus/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-58ba46071304>\", line 1, in <module>\n",
      "    np_grouped = np_files.reshape(round(np_files.shape[0]/4), 4)\n",
      "ValueError: cannot reshape array of size 85197 into shape (21299,4)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/felipematheus/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/felipematheus/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/felipematheus/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/felipematheus/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/felipematheus/anaconda3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/felipematheus/anaconda3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/felipematheus/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/felipematheus/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "AttributeError: module has no attribute '__name__'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 85197 into shape (21299,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "np_grouped = np_files.reshape(round(np_files.shape[0]/4), 4)\n",
    "class_id = []\n",
    "#CHANGE HERE THE INDEX EVERYTIME WE CHANGE THE NAME FROM THE PATH OF THE FOLDER\n",
    "for g in np_grouped:\n",
    "    class_id = class_id + [[g[0][-20:-12], g[0][-12:-8]]] \n",
    "types = []\n",
    "types_bool = []\n",
    "for ids in class_id:\n",
    "    types = types + [conversion[ids[1]]]\n",
    "    types_bool = types_bool + [conversion_bool[ids[1]]]\n",
    "    \n",
    "astr_objs = []\n",
    "for i in range(len(np_grouped)):\n",
    "    astr_objs = astr_objs + [class_id[i]]\n",
    "    for file in np_grouped[i]:\n",
    "        img = Image.open(file).convert('L')\n",
    "        arr = np.array(img)\n",
    "        astr_objs[-1] = astr_objs[-1] + [arr[5:35,10:56]] \n",
    "        #CHANGE HERE IF WE EVENTUALLY CHANGE THE SIZE OF THE IMAGE, OR WANT TO CUT OTHER FRAMES\n",
    "\n",
    "print( \"The quantity of objects is: \", len(astr_objs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 4264  4265  4266 ... 21313 21314 21315] TEST: [   0    1    2 ... 4261 4262 4263]\n",
      "TRAIN: [    0     1     2 ... 21313 21314 21315] TEST: [4264 4265 4266 ... 8524 8525 8526]\n",
      "TRAIN: [    0     1     2 ... 21313 21314 21315] TEST: [ 8527  8528  8529 ... 12787 12788 12789]\n",
      "TRAIN: [    0     1     2 ... 21313 21314 21315] TEST: [12790 12791 12792 ... 17050 17051 17052]\n",
      "TRAIN: [    0     1     2 ... 17050 17051 17052] TEST: [17053 17054 17055 ... 21313 21314 21315]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "images = []\n",
    "ids = []\n",
    "for o in astr_objs:\n",
    "    labels.append((conversion_bool[o[1]])) #converting here to numbers to assure label in training\n",
    "    images.append(o[2:])\n",
    "    ids.append(o[0])\n",
    "labels = np.asarray(labels)\n",
    "images = np.asarray(images)\n",
    "ids = np.asarray(ids)\n",
    "\n",
    "Xb = images\n",
    "yb = labels\n",
    "kfb = KFold(n_splits=5)\n",
    "Xb_train = []\n",
    "Xb_test = []\n",
    "yb_train = []\n",
    "yb_test = []\n",
    "id_train = []\n",
    "id_test = []\n",
    "for train_index, test_index in kfb.split(Xb):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xb_train.append(Xb[train_index])\n",
    "    Xb_test.append(Xb[test_index])\n",
    "    yb_train.append(yb[train_index])\n",
    "    yb_test.append(yb[test_index])\n",
    "    id_train.append(ids[train_index])\n",
    "    id_test.append(ids[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the objects are:\n",
      "ids:  (21316,)\n",
      "labels:  (21316,)\n",
      "images:  (21316, 4, 30, 46)\n",
      "train_images:  (17052, 4, 30, 46)\n",
      "Other useful object: \"test_images\"\n"
     ]
    }
   ],
   "source": [
    "print('The shapes of the objects are:')\n",
    "print('ids: ', ids.shape)\n",
    "print('labels: ', labels.shape)\n",
    "print('images: ', images.shape)\n",
    "print('train_images: ', Xb_train[0].shape)\n",
    "print('Other useful object: \"test_images\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell bugs the pc a little\n",
    "#Normalization and separating the folds to the models\n",
    "train_images = np.around(Xb_train[0]/255, decimals = 2)\n",
    "test_images = np.around(Xb_test[0]/255, decimals = 2)\n",
    "\n",
    "train_swaped = np.swapaxes(train_images,1,3)\n",
    "test_swaped = np.swapaxes(test_images,1,3)\n",
    "\n",
    "\n",
    "\n",
    "train_images4 = np.around(Xb_train[4]/255, decimals = 2)\n",
    "test_images4 = np.around(Xb_test[4]/255, decimals = 2)\n",
    "\n",
    "train_swaped4 = np.swapaxes(train_images4,1,3)\n",
    "test_swaped4 = np.swapaxes(test_images4,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Convolution NN 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/felipematheus/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 30, 64)        4160      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 46, 30, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4928)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 39432     \n",
      "=================================================================\n",
      "Total params: 117,448\n",
      "Trainable params: 117,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "img_rows, img_cols = 30, 46\n",
    "input_shape = (img_cols, img_rows, 4)\n",
    "\n",
    "model_cv = Sequential()\n",
    "\n",
    "model_cv.add(Conv2D(64, kernel_size=(4,4), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_cv.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model_cv.add(Flatten())\n",
    "model_cv.add(Dense(8, activation=tf.nn.softmax))\n",
    "\n",
    "model_cv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9)\n",
    "model_cv.compile(optimizer='adam', #optimizer = 'adadelta'\n",
    "              loss='sparse_categorical_crossentropy', #loss = \"binary_crossentropy\"\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9)\n",
    "model_cv.fit(train_swaped, yb_train[0], #validation_split = 0.1\n",
    "             epochs=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Kfold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9)\n",
    "img_rows, img_cols = 30, 46\n",
    "input_shape = (img_cols, img_rows, 4)\n",
    "\n",
    "model_cv4 = Sequential()\n",
    "\n",
    "model_cv4.add(Conv2D(64, kernel_size=(4,4), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv4.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_cv4.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model_cv4.add(Flatten())\n",
    "model_cv4.add(Dense(8, activation=tf.nn.softmax))\n",
    "\n",
    "model_cv4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9)\n",
    "model_cv4.compile(optimizer='adam', #optimizer = 'adadelta'\n",
    "              loss='sparse_categorical_crossentropy', #loss = \"binary_crossentropy\"\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17053/17053 [==============================] - 127s 7ms/sample - loss: 0.2693 - acc: 0.8747\n",
      "Epoch 2/10\n",
      "17053/17053 [==============================] - 130s 8ms/sample - loss: 0.2596 - acc: 0.8805\n",
      "Epoch 3/10\n",
      "17053/17053 [==============================] - 128s 8ms/sample - loss: 0.2495 - acc: 0.8830\n",
      "Epoch 4/10\n",
      "17053/17053 [==============================] - 131s 8ms/sample - loss: 0.2439 - acc: 0.8866\n",
      "Epoch 5/10\n",
      "17053/17053 [==============================] - 131s 8ms/sample - loss: 0.2388 - acc: 0.8905\n",
      "Epoch 6/10\n",
      "17053/17053 [==============================] - 132s 8ms/sample - loss: 0.2338 - acc: 0.8922\n",
      "Epoch 7/10\n",
      "17053/17053 [==============================] - 131s 8ms/sample - loss: 0.2274 - acc: 0.8957\n",
      "Epoch 8/10\n",
      "17053/17053 [==============================] - 130s 8ms/sample - loss: 0.2199 - acc: 0.8984\n",
      "Epoch 9/10\n",
      "17053/17053 [==============================] - 135s 8ms/sample - loss: 0.2154 - acc: 0.9032\n",
      "Epoch 10/10\n",
      "17053/17053 [==============================] - 136s 8ms/sample - loss: 0.2082 - acc: 0.9076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f77cceae9b0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "model_cv4.fit(train_swaped4, yb_train[4], #validation_split = 0.1\n",
    "             epochs=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4264/4264 [==============================] - 11s 3ms/sample - loss: 0.2882 - acc: 0.8659\n",
      "Test accuracy model_cv: 0.86585367\n",
      "Test loss model_cv: 0.28823974298044175\n"
     ]
    }
   ],
   "source": [
    "test_loss_cv, test_acc_cv = model_cv.evaluate(test_swaped, yb_test[0])\n",
    "\n",
    "print('Test accuracy model_cv:', test_acc_cv)\n",
    "print('Test loss model_cv:', test_loss_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4263/4263 [==============================] - 11s 3ms/sample - loss: 0.3058 - acc: 0.8677\n",
      "Test accuracy model_cv: 0.8676988\n",
      "Test loss model_cv: 0.3057690264332499\n"
     ]
    }
   ],
   "source": [
    "test_loss_cv4, test_acc_cv4 = model_cv4.evaluate(test_swaped4, yb_test[4])\n",
    "\n",
    "print('Test accuracy model_cv:', test_acc_cv4)\n",
    "print('Test loss model_cv:', test_loss_cv4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
