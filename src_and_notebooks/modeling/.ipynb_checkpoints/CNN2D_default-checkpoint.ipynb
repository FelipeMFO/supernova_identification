{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../processing/read_data.py\n",
    "%run ../processing/functions.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_read = '../../data/dl_marcelo_no_treat/'\n",
    "files = []\n",
    "\n",
    "for r, d, f in os.walk(path_to_read):\n",
    "    for file in f:\n",
    "        if '.png' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "files.sort()\n",
    "np_files = np.asarray(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Verification if each transient has 4 curves\n",
    "#temp = 'SN000017'\n",
    "#count = 0\n",
    "#for f in np_files:\n",
    "#    if (count == 4):\n",
    "#        temp = f[40:48]\n",
    "#        count = 0\n",
    "#    if ((temp == f[40:48]) & (count < 4)):\n",
    "#        count += 1\n",
    "#    elif ((temp != f[40:48]) & (count < 4)):\n",
    "#        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(types) -> {'IIL', 'IIP', 'II_', 'IIn', 'Ia_', 'Ib_', 'Ibc', 'Ic_'}\n",
    "#conversion = {'IIL' : 5, 'IIP' : 7, 'II_' : 4, 'IIn' : 6, 'Ia_' : 0, 'Ib_' : 1, 'Ibc' : 2, 'Ic_' : 3}\n",
    "\n",
    "conversion = {'IIL_' : 5, 'IIP_' : 7, '_II_' : 4, 'IIn_' : 6, '_Ia_' : 0, '_Ib_' : 1, 'Ibc_' : 2, '_Ic_' : 3}\n",
    "conversion_bool = {'IIL_' : 0, 'IIP_' : 0, '_II_' : 0, 'IIn_' : 0, '_Ia_' : 1, '_Ib_' : 0, 'Ibc_' : 0, '_Ic_' : 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_grouped = np_files.reshape(round(np_files.shape[0]/4), 4)\n",
    "class_id = []\n",
    "#CHANGE HERE THE INDEX EVERYTIME WE CHANGE THE NAME FROM THE PATH OF THE FOLDER\n",
    "for g in np_grouped:\n",
    "    class_id = class_id + [[g[0][-20:-12], g[0][-12:-8]]] \n",
    "types = []\n",
    "types_bool = []\n",
    "for ids in class_id:\n",
    "    types = types + [conversion[ids[1]]]\n",
    "    types_bool = types_bool + [conversion_bool[ids[1]]]\n",
    "    \n",
    "astr_objs = []\n",
    "for i in range(len(np_grouped)):\n",
    "    astr_objs = astr_objs + [class_id[i]]\n",
    "    for file in np_grouped[i]:\n",
    "        img = Image.open(file).convert('L')\n",
    "        arr = np.array(img)\n",
    "        astr_objs[-1] = astr_objs[-1] + [arr[5:35,10:56]] \n",
    "        #CHANGE HERE IF WE EVENTUALLY CHANGE THE SIZE OF THE IMAGE, OR WANT TO CUT OTHER FRAMES\n",
    "\n",
    "print( \"The quantity of objects is: \", len(astr_objs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 4264  4265  4266 ... 21313 21314 21315] TEST: [   0    1    2 ... 4261 4262 4263]\n",
      "TRAIN: [    0     1     2 ... 21313 21314 21315] TEST: [4264 4265 4266 ... 8524 8525 8526]\n",
      "TRAIN: [    0     1     2 ... 21313 21314 21315] TEST: [ 8527  8528  8529 ... 12787 12788 12789]\n",
      "TRAIN: [    0     1     2 ... 21313 21314 21315] TEST: [12790 12791 12792 ... 17050 17051 17052]\n",
      "TRAIN: [    0     1     2 ... 17050 17051 17052] TEST: [17053 17054 17055 ... 21313 21314 21315]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "images = []\n",
    "ids = []\n",
    "for o in astr_objs:\n",
    "    labels.append((conversion_bool[o[1]])) #converting here to numbers to assure label in training\n",
    "    images.append(o[2:])\n",
    "    ids.append(o[0])\n",
    "labels = np.asarray(labels)\n",
    "images = np.asarray(images)\n",
    "ids = np.asarray(ids)\n",
    "\n",
    "Xb = images\n",
    "yb = labels\n",
    "kfb = KFold(n_splits=5)\n",
    "Xb_train = []\n",
    "Xb_test = []\n",
    "yb_train = []\n",
    "yb_test = []\n",
    "id_train = []\n",
    "id_test = []\n",
    "for train_index, test_index in kfb.split(Xb):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xb_train.append(Xb[train_index])\n",
    "    Xb_test.append(Xb[test_index])\n",
    "    yb_train.append(yb[train_index])\n",
    "    yb_test.append(yb[test_index])\n",
    "    id_train.append(ids[train_index])\n",
    "    id_test.append(ids[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the objects are:\n",
      "ids:  (21316,)\n",
      "labels:  (21316,)\n",
      "images:  (21316, 4, 30, 46)\n",
      "train_images:  (17052, 4, 30, 46)\n",
      "Other useful object: \"test_images\"\n"
     ]
    }
   ],
   "source": [
    "print('The shapes of the objects are:')\n",
    "print('ids: ', ids.shape)\n",
    "print('labels: ', labels.shape)\n",
    "print('images: ', images.shape)\n",
    "print('train_images: ', Xb_train[0].shape)\n",
    "print('Other useful object: \"test_images\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell bugs the pc a little\n",
    "train_images = np.around(Xb_train[0]/255, decimals = 2)\n",
    "test_images = np.around(Xb_test[0]/255, decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Conv3D, MaxPooling3D, ZeroPadding3D\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Convolution NN 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/felipematheus/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 30, 64)        4160      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 46, 30, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4928)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 39432     \n",
      "=================================================================\n",
      "Total params: 117,448\n",
      "Trainable params: 117,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 30, 46\n",
    "input_shape = (img_cols, img_rows, 4)\n",
    "\n",
    "model_cv = Sequential()\n",
    "\n",
    "model_cv.add(Conv2D(64, kernel_size=(4,4), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_cv.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model_cv.add(Flatten())\n",
    "model_cv.add(Dense(8, activation=tf.nn.softmax))\n",
    "\n",
    "model_cv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv.compile(optimizer='adam', #optimizer = 'adadelta'\n",
    "              loss='sparse_categorical_crossentropy', #loss = \"binary_crossentropy\"\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_swaped = np.swapaxes(train_images,1,3)\n",
    "test_swaped = np.swapaxes(test_images,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17052/17052 [==============================] - 171s 10ms/sample - loss: 0.5020 - acc: 0.7654\n",
      "Epoch 2/10\n",
      "17052/17052 [==============================] - 130s 8ms/sample - loss: 0.3726 - acc: 0.8113\n",
      "Epoch 3/10\n",
      "17052/17052 [==============================] - 147s 9ms/sample - loss: 0.3351 - acc: 0.8373\n",
      "Epoch 4/10\n",
      "17052/17052 [==============================] - 134s 8ms/sample - loss: 0.3147 - acc: 0.8495\n",
      "Epoch 5/10\n",
      "17052/17052 [==============================] - 128s 8ms/sample - loss: 0.3031 - acc: 0.8567\n",
      "Epoch 6/10\n",
      "17052/17052 [==============================] - 130s 8ms/sample - loss: 0.2928 - acc: 0.8613\n",
      "Epoch 7/10\n",
      "17052/17052 [==============================] - 129s 8ms/sample - loss: 0.2822 - acc: 0.8666\n",
      "Epoch 8/10\n",
      "17052/17052 [==============================] - 129s 8ms/sample - loss: 0.2782 - acc: 0.8689\n",
      "Epoch 9/10\n",
      "17052/17052 [==============================] - 131s 8ms/sample - loss: 0.2689 - acc: 0.8737\n",
      "Epoch 10/10\n",
      "17052/17052 [==============================] - 130s 8ms/sample - loss: 0.2625 - acc: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f77ce762ac8>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "model_cv.fit(train_swaped, yb_train[0], #validation_split = 0.1\n",
    "             epochs=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the other Kfold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images4 = np.around(Xb_train[4]/255, decimals = 2)\n",
    "test_images4 = np.around(Xb_test[4]/255, decimals = 2)\n",
    "\n",
    "train_swaped4 = np.swapaxes(train_images4,1,3)\n",
    "test_swaped4 = np.swapaxes(test_images4,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17053/17053 [==============================] - 127s 7ms/sample - loss: 0.2693 - acc: 0.8747\n",
      "Epoch 2/10\n",
      "17053/17053 [==============================] - 130s 8ms/sample - loss: 0.2596 - acc: 0.8805\n",
      "Epoch 3/10\n",
      "17053/17053 [==============================] - 128s 8ms/sample - loss: 0.2495 - acc: 0.8830\n",
      "Epoch 4/10\n",
      "17053/17053 [==============================] - 131s 8ms/sample - loss: 0.2439 - acc: 0.8866\n",
      "Epoch 5/10\n",
      "17053/17053 [==============================] - 131s 8ms/sample - loss: 0.2388 - acc: 0.8905\n",
      "Epoch 6/10\n",
      "17053/17053 [==============================] - 132s 8ms/sample - loss: 0.2338 - acc: 0.8922\n",
      "Epoch 7/10\n",
      "17053/17053 [==============================] - 131s 8ms/sample - loss: 0.2274 - acc: 0.8957\n",
      "Epoch 8/10\n",
      "17053/17053 [==============================] - 130s 8ms/sample - loss: 0.2199 - acc: 0.8984\n",
      "Epoch 9/10\n",
      "17053/17053 [==============================] - 135s 8ms/sample - loss: 0.2154 - acc: 0.9032\n",
      "Epoch 10/10\n",
      "17053/17053 [==============================] - 136s 8ms/sample - loss: 0.2082 - acc: 0.9076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f77cceae9b0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "model_cv.fit(train_swaped4, yb_train[4], #validation_split = 0.1\n",
    "             epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4264/4264 [==============================] - 11s 3ms/sample - loss: 0.2882 - acc: 0.8659\n",
      "Test accuracy model_cv: 0.86585367\n",
      "Test loss model_cv: 0.28823974298044175\n"
     ]
    }
   ],
   "source": [
    "test_loss_cv, test_acc_cv = model_cv.evaluate(test_swaped, yb_test[0])\n",
    "\n",
    "print('Test accuracy model_cv:', test_acc_cv)\n",
    "print('Test loss model_cv:', test_loss_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4263/4263 [==============================] - 11s 3ms/sample - loss: 0.3058 - acc: 0.8677\n",
      "Test accuracy model_cv: 0.8676988\n",
      "Test loss model_cv: 0.3057690264332499\n"
     ]
    }
   ],
   "source": [
    "test_loss_cv4, test_acc_cv4 = model_cv.evaluate(test_swaped4, yb_test[4])\n",
    "\n",
    "print('Test accuracy model_cv:', test_acc_cv4)\n",
    "print('Test loss model_cv:', test_loss_cv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 46, 30, 64)        4160      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 46, 30, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 23, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4928)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 39432     \n",
      "=================================================================\n",
      "Total params: 117,448\n",
      "Trainable params: 117,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 30, 46\n",
    "input_shape = (img_cols, img_rows, 4)\n",
    "\n",
    "model_cv = Sequential()\n",
    "\n",
    "model_cv.add(Conv2D(64, kernel_size=(4,4), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_cv.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model_cv.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model_cv.add(Flatten())\n",
    "model_cv.add(Dense(8, activation=tf.nn.softmax))\n",
    "\n",
    "model_cv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv.compile(optimizer='adam', #optimizer = 'adadelta'\n",
    "              loss='sparse_categorical_crossentropy', #loss = \"binary_crossentropy\"\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17053/17053 [==============================] - 135s 8ms/sample - loss: 0.5028 - acc: 0.7681\n",
      "Epoch 2/10\n",
      "17053/17053 [==============================] - 130s 8ms/sample - loss: 0.3753 - acc: 0.8108\n",
      "Epoch 3/10\n",
      "17053/17053 [==============================] - 127s 7ms/sample - loss: 0.3390 - acc: 0.8372\n",
      "Epoch 4/10\n",
      "17053/17053 [==============================] - 126s 7ms/sample - loss: 0.3231 - acc: 0.8445\n",
      "Epoch 5/10\n",
      "17053/17053 [==============================] - 130s 8ms/sample - loss: 0.3049 - acc: 0.8540\n",
      "Epoch 6/10\n",
      "17053/17053 [==============================] - 129s 8ms/sample - loss: 0.2952 - acc: 0.8601\n",
      "Epoch 7/10\n",
      "17053/17053 [==============================] - 127s 7ms/sample - loss: 0.2873 - acc: 0.8644\n",
      "Epoch 8/10\n",
      "17053/17053 [==============================] - 128s 8ms/sample - loss: 0.2806 - acc: 0.8688\n",
      "Epoch 9/10\n",
      "17053/17053 [==============================] - 129s 8ms/sample - loss: 0.2757 - acc: 0.8714\n",
      "Epoch 10/10\n",
      "17053/17053 [==============================] - 126s 7ms/sample - loss: 0.2664 - acc: 0.8752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f77314ac588>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "model_cv.fit(train_swaped4, yb_train[4], #validation_split = 0.1\n",
    "             epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4263/4263 [==============================] - 11s 3ms/sample - loss: 0.3133 - acc: 0.8583\n",
      "Test accuracy model_cv: 0.85831577\n",
      "Test loss model_cv: 0.31331894346981465\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "test_loss_cv4, test_acc_cv4 = model_cv.evaluate(test_swaped4, yb_test[4])\n",
    "\n",
    "print('Test accuracy model_cv:', test_acc_cv4)\n",
    "print('Test loss model_cv:', test_loss_cv4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.85831577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = []\n",
    "#images = []\n",
    "#ids = []\n",
    "#for o in astr_objs:\n",
    "#    labels.append((conversion_bool[o[1]])) #converting here to numbers to assure label in training\n",
    "#    images.append(o[2:])\n",
    "#    ids.append(o[0])\n",
    "#labels = np.asarray(labels)\n",
    "#images = np.asarray(images)\n",
    "#ids = np.asarray(ids)\n",
    "#\n",
    "#train_n = 18000\n",
    "#\n",
    "#train_labels = labels[0:train_n]\n",
    "#test_labels = labels[train_n:]\n",
    "#\n",
    "#train_images = images[0:train_n]\n",
    "#test_images = images[train_n:]\n",
    "#\n",
    "#train_ids = ids[0:train_n]\n",
    "#test_ids = ids[train_n:]\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
